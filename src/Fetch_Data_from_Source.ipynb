{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332e6d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1eb842",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_OFFERING_DATA_WEB_PATH = \"https://www.cs.cmu.edu/~jiweil/offering.txt.zip\"\n",
    "SOURCE_REVIEW_DATA_WEB_PATH = \"https://www.cs.cmu.edu/~jiweil/review.txt.zip\"\n",
    "\n",
    "os.makedirs(os.path.dirname(\"./../Input_Data/\"), exist_ok=True)\n",
    "OFFERING_DATA_FILEPATH = \"./../Input_Data/offering.zip\"\n",
    "REVIEW_DATA_FILEPATH = \"./../Input_Data/review.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0948d58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Offering dataset from web\n",
    "response = requests.get(SOURCE_OFFERING_DATA_WEB_PATH)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open(OFFERING_DATA_FILEPATH, \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "    print(\"Offering data downloaded successfully!\")\n",
    "else:\n",
    "    print(f\"Failed to download Offering data from source. Status code: {response.status_code}\")\n",
    "\n",
    "    \n",
    "# Fetch Review dataset from web\n",
    "# response = requests.get(SOURCE_REVIEW_DATA_WEB_PATH)\n",
    "\n",
    "# if response.status_code == 200:\n",
    "#     with open(REVIEW_DATA_FILEPATH, \"wb\") as file:\n",
    "#         file.write(response.content)\n",
    "#     print(\"Review data downloaded successfully!\")\n",
    "# else:\n",
    "#     print(f\"Failed to download Review data from source. Status code: {response.status_code}\")\n",
    "\n",
    "with requests.get(SOURCE_REVIEW_DATA_WEB_PATH, stream=True) as r:\n",
    "        with open(REVIEW_DATA_FILEPATH, 'wb') as f:\n",
    "            shutil.copyfileobj(r.raw, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1432ce6",
   "metadata": {},
   "source": [
    "## Reading in the review and offerings data using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd09a309",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data_pd = pd.read_json(REVIEW_DATA_FILEPATH, lines = True)\n",
    "# review_data_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975f40d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "offerings_data_pd = pd.read_json(OFFERING_DATA_FILEPATH, lines = True)\n",
    "# offerings_data_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c841d1",
   "metadata": {},
   "source": [
    "## Extract the individual values from columns that have dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad5a228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate the 'ratings' column, so that the dictionary within it can be split into individual columns\n",
    "reviews_ratings = pd.DataFrame(review_data_pd['ratings'])\n",
    "reviews_ratings_normalized = pd.json_normalize(reviews_ratings['ratings'])\n",
    "\n",
    "# reviews_ratings_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec52eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate the 'authors' column from review_data_pd, so that the dictionary within it can be split into individual columns\n",
    "reviews_author = pd.DataFrame(review_data_pd['author'])\n",
    "reviews_author_normalized = pd.json_normalize(reviews_author['author'])\n",
    "# rename the id column in auther so that it can be recognized\n",
    "reviews_author_normalized = reviews_author_normalized.rename(columns = {'id': 'author_id'})\n",
    "# reviews_author_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ab8d6f",
   "metadata": {},
   "source": [
    "## Remake the original dataframes with split out dictionaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddac682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add all the split out data back to the original review_data_pd dataframe\n",
    "review_data_updated = pd.concat([review_data_pd, reviews_ratings_normalized], axis = 1)\n",
    "review_data_updated = pd.concat([review_data_updated, reviews_author_normalized], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f229fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the original dictionary columns \"author\" and \"ratings\" (since we have all the data split out now)\n",
    "review_data_updated = review_data_updated.drop(columns = ['author'])\n",
    "review_data_updated = review_data_updated.drop(columns = ['ratings'])\n",
    "\n",
    "# review_data_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bbe63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate the 'address' column from offerings_data_pd, so that the dictionary within it can be split into individual columns\n",
    "offerings_address = pd.DataFrame(offerings_data_pd['address'])\n",
    "offerings_address_normalized = pd.json_normalize(offerings_address['address'])\n",
    "\n",
    "# offerings_address_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebc0724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add all the split out data back to the original offering_data_pd dataframe\n",
    "offerings_data_updated = pd.concat([offerings_data_pd, offerings_address_normalized], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fcfcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the original address dictionary column (since we have all the data split out now)\n",
    "offerings_data_updated = offerings_data_updated.drop(columns = ['address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417cf73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming the ID column so that we can merge the two datasets together\n",
    "offerings_data_updated = offerings_data_updated.rename(columns = {'id': 'offering_id'})\n",
    "\n",
    "# offerings_data_updated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06731c91",
   "metadata": {},
   "source": [
    "## Merging the offerings and reviews datasets together for final dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3e2c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_offerings_reviews = pd.merge(review_data_updated, offerings_data_updated, on = 'offering_id')\n",
    "\n",
    "# merged_offerings_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6c5a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write complete merged dataframe as gzipped CSV file\"\n",
    "merged_offerings_reviews.to_csv(\"./../processed_data/original_data_merged.csv.gz\", index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cec19e9",
   "metadata": {},
   "source": [
    "## Final output: original_data_merged.csv.gz\n",
    "\n",
    "### Next step: Filter review text language (performed in language_filtering.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
