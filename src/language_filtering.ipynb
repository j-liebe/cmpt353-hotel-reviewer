{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5364aa8",
   "metadata": {},
   "source": [
    "## language_filtering.ipynb\n",
    "### Jenna Liebe, Setu Patel\n",
    "This code imports the original_data_merged.csv.gz file (combined reviews and offering data with dictionary columns split out), and then isolates the comments (id, title, text) in a new file, review_comments.json.\n",
    "\n",
    "From there, review_comments.json is read in by Spark, and the language is detected using the langid library for each comment. Only those comments with a language of 'en' (English) or 'null' are kept. A join is then performed with original_data, to recover all the dataset columns, but only keeping the filtered English comments.\n",
    "\n",
    "Finally, this English-filtered dataset is printed to english_data.csv.gz for further processing.\n",
    "\n",
    "* Note: Filtering by just 'en' removed too many comments, so those marked 'null' (as in, the filter couldn't confidently determine the language) were also kept. For the most part, these are all English. The few that aren't will be handled by the sentiment analysis model later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939135ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import langid\n",
    "import re\n",
    "from pyspark.sql import SparkSession, functions, types\n",
    "from pyspark.sql.functions import col, when, coalesce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f921d0",
   "metadata": {},
   "source": [
    "### Generate comments json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0584d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_DATA_PATH = \"./../processed_data/original_data_merged.csv.gz\"\n",
    "REGEX_CLEANING_PATTERN = \"[^0-9a-zA-Z\\s]+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ef94e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_csv(ORIGINAL_DATA_PATH, low_memory=False, dtype={'title': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d195e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Customer review comment title, text and id as unique identifier\n",
    "all_review_comments_pd = original_data[[\"title\", \"text\", \"id\"]]\n",
    "\n",
    "#all_review_comments_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00afd852",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_review_comments_pd.to_json(\"./../processed_data/review_comments.json\",orient = 'records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257701f5",
   "metadata": {},
   "source": [
    "### Use Spark to read in review_comments.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dd79b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up Spark stuff\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Translate Non-English Text\") \\\n",
    "    .config('spark.driver.memory', '8g') \\\n",
    "    .config('spark.executor.memory', '8g') \\\n",
    "    .config('spark.network.timeout', '600000') \\\n",
    "    .config('spark.sql.broadcastTimeout', '600000') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "392b5b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema for review_comments.json\n",
    "comments_schema = types.StructType([\n",
    "    types.StructField('title', types.StringType()),\n",
    "    types.StructField('text', types.StringType()),\n",
    "    types.StructField('id', types.StringType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aba010a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_comments = spark.read.load(\"./../processed_data/review_comments.json\", format=\"json\", schema = comments_schema).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a908f39f",
   "metadata": {},
   "source": [
    "### Language filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de425c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# language detection function\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        language, confidence = langid.classify(text)\n",
    "        return language if confidence > 0.5 else None\n",
    "    except: return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "468caca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_language_udf = functions.udf(detect_language, types.StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ef34035",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_comment_ids = spark_comments.withColumn('language', detect_language_udf(col('title'))) \\\n",
    "                                 .where((col('language') == 'en') | (col('language') == 'null')) \\\n",
    "                                 .select('id') \\\n",
    "                                 .cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f64b0e1",
   "metadata": {},
   "source": [
    "### Convert to Pandas DF for printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e06b91db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_comment_ids = english_comment_ids.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a374cea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't need Spark anymore, so may as well stop it\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54a33063",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_comment_ids.rename(columns = {'id': 'comment_id'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5a09512",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(original_data.columns)\n",
    "cols[6] = 'comment_id'\n",
    "original_data.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9acab968",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_comment_ids['comment_id'] = pandas_comment_ids['comment_id'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0fcb2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_data = original_data.merge(pandas_comment_ids, on = 'comment_id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0aff137",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_data.to_csv('./../processed_data/english_data.csv.gz', index = False, compression = 'gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957d0504",
   "metadata": {},
   "source": [
    "### Final output: english_data.csv.gz \n",
    "#### (header + 147,034 rows, ~52MB compressed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
